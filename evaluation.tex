\documentclass[dissertation.tex]{subfiles}

\begin{document}

\section{Success Criteria}
{

    The success criteria laid out in the project proposal have all been satisfied:

    \begin{itemize}
    \item Translate simple Haskell programs into executable Java bytecode.
    \item Reject ill-formed programs due to syntactic or type errors.
    \item Perform simple optimisations during translation.
    \item Perform evaluation using non-strict semantics.
    \end{itemize}
    
    Beyond these base requirements, a number of the extensions implementing language features have been completed
    successfully.

    \todo[inline]{Mention somewhere pros/cons of using JVB}
}
\section{Language Features}
{

    The planned subset of Haskell was functions, arithmetic, booleans, lists, simple typeclasses, and laziness. The
    following program demonstrates various use-cases of all of these features:

    \begin{haskellfigure}
    -- foldl :: (b -> a -> b) -> b -> [a] -> b
    foldl _ e [] = e
    foldl f e (x:xs) = foldl f (f e x) xs

    -- sum :: Num a => [a] -> a
    sum = foldl (+) 0

    -- take :: Int -> [a] -> [a]
    take 0 _ = []
    take _ [] = undefined
    take n (x:xs) = x:take (n-1) xs

    -- ones :: Num a => [a]
    ones = 1:ones

    -- valid :: Bool
    valid = sum (take 10 ones :: [Int]) == 10
    \end{haskellfigure}

    Successfuly implemented extensions include support for user-defined datatypes, user-defined typeclasses and
    instances, monads, and some syntactic features like operator sections and support for point-free notation: these can
    be demonstrated by the following program:

    \todo[inline]{Hard to give an example program using monads without ending up doing a monad tutorial!}
    \begin{haskellfigure}
    data Maybe a = Nothing | Just a
    data [] a = [] | a:[a]
    
    class Monad m where
        (>>=) :: m a -> (a -> m b) -> m b
        return :: a -> m a
    instance Monad Maybe where
        Nothing >>= f = Nothing
        (Just x) >>= f = f x
        return = Just
    instance Monad [] where
        [] >>= f = []
        (x:xs) >>= f = (f x) ++ (f >>= xs)
        return x = [x]

    -- The monad instance for maybe can be interpreted as function application
    -- with support for chaining failure
    divide x y = if y == 0 then Nothing else Just (x / y)
    x = divide 4 0 >>= divide 20 -- Evaluates to Nothing

    -- The monad instance for lists can be interpreted as performing
    -- non-deterministic computation: each step can have multiple results
    countdown 0 = []
    countdown n = n:countdown (n - 1)
    onlyEven x = if even x then [x] else []
    y = [1,2,3] >>= countdown -- Evaluates to [1,2,1,3,2,1]
    z = y >>= onlyEven -- Evaluates to [2,2]
    \end{haskellfigure}

    \todo[inline]{Double triple check these programs work (add to tests) as it'd be really awkward if someone tries to test them and they don't...}

    Each simple feature name necessarily glosses over many smaller constituent features necessary for use. For example,
    the `lists' feature allows for lists to be created using either the plain constructor syntax
    (\haskell{1:(2:(3:[]))}) or syntactic sugar for lists (\haskell{[1,2,3]}), and matched using patterns (eg.\
    \haskell{[x,y] = [1,2]}). However, there's no support for list comprehensions (eg.\ \haskell{[f x | x <- [1,2,3],
    even x]}) as they weren't a high priority feature.

    \todo[inline]{This \^ paragraph is kinda trying to explain that there's a lot of things associated with each coarse `feature', and that I've implemented all the obvious ones but that there are other aspects I won't have implemented. Unnecessary?}

    \todo[inline]{Should I talk about missing features? Typeclass/instance superclasses, default method implementations in classes, symbol type signatures...}
    
    \subsubsection{Correctness}
    {

        Correctness of the various stages of the compiler has been empirically tested using a large set of unit and
        integration tests: these include tests of complete programs, such as those used for benchmarking.
        
        At the time of writing, there are 245\todo{Update} tests. These are run both on my development machine
        (described in \ref{sec:test-environment}), and on machines provided by Travis
        CI\footnote{\url{https://travis-ci.org/hnefatl/dissertation-project}} whenever a commit is pushed to my
        development GitHub repository. This ensures the compiler works in a clean, reproducible environment and not just
        on my development system.
        
    }
}
\section{Performance}
{

    \subsubsection{Test Environment}\label{sec:test-environment}
    {

        Benchmarks were performed as the only active process on my development machine: a ThinkPad 13 running Debian 9
        with 8GB RAM and an Intel Core i5-7200U CPU (2.5GHz).

    }

    Bar charts of speed + code size + compilation time + maybe memory allocation if I can measure it comparing my
    compiler to Frege and Eta, other Haskell->JVM compilers. Including compilation time because it looks like one thing
    my compiler is good at, it gets destroyed in performance.

    Heatmap plot showing speedup (heat) achieved by different combinations of optimisations (y axis) against benchmarks
    (x axis) for my compiler.

    Can conclude that my implementation of thunks is inefficient, compare to Frege/Eta's implementation. Think they both
    use loads of anonymous classes for their implementations while mine avoids that: can frame it as `I tried a
    different approach and found it was less performant', not necessarily a bad thing as speed was never a focus, and
    make guesses (and call them hypotheses) as to why their version is better.

    % Graphs
    % - Execution time 
    % - Code size
    % - Memory allocation? Hard to measure with frameworks
    % Test machine spec
    % How were tests performed? JMH



}
\section{Schedule}
{

    \todo[inline]{This is a WIP rehash of the stuff from the progress report explaining why the schedule got messed up, I feel it'll help explain why optimisations didn't get much splotlight.}

    The core features of Haskell are tightly coupled: simple features such as arithmetic operators require a significant
    level of support for other language features. For example, the \haskell{(+)} function relies on:

    \begin{description}
    \item[Typeclasses:] \haskell{(+)} is defined by the \haskell{Num} typeclass in order to allow ad-hoc overloading.
    \item[Typeclass instances:]
    {
        The types that can be used as arguments to the overloaded functions, and the implementation of the overloads,
        are defined by typeclass instances.
    }
    \item[Datatypes:]
    {
        The most common implementation of typeclasses involves translating classes into datatypes and instances into
        values of the datatype.
    }
    \end{description}

    It would be possible to implement a function like \haskell{(+)} which only worked for integers and avoid all of the
    dependencies on other language features, but then the language simply wouldn't be Haskell: it would resemble a lazy
    variant of ML's semantics.

    All of these language features are very expensive to implement, as they span multiple layers of the compiler: the
    type checker needs to be able to infer and check types based on the usage of these features, they need to be
    translatable into intermediate languages, and the code generator needs to be able to produce bytecode reflecting the
    semantics.

}




\end{document}