\documentclass[dissertation.tex]{subfiles}

\begin{document}

The compiler is comprised of a number of stages and substages, as shown in Figure \ref{fig:compiler-layout}:

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/compiler_layout.png}
    \caption{}
    \label{fig:compiler-layout}
\end{figure}

A brief overview of each stage is given here for a `big picture' view of the compiler, followed by more detailed
descriptions below.

\begin{description}
\item[Frontend]
{
    \hfill

    The frontend consists of standard lexing and parsing from Haskell source code into an Abstract Syntax Tree
    (AST). A modified version of an existing library (haskell-src\footnote{https://github.com/hnefatl/haskell-src})
    is used.

}
\item[Preprocessing]
{
    \hfill
    \begin{itemize}
    \item
    {

        The renamer renames each variable so that later stages can assume each variable name is unique:
        this reduces complexity by removing the possibility of variable shadowing (eg.\ \haskell{let x = 1 in let x
        = 2 in x}).

    }
    \item
    {

        Kind and Class analysis both simply extract useful information about the declarations in the source so that
        stages of the type checker are simpler.

    }
    \item
    {

        Dependency analysis computes a partial order on the source declarations so that the typechecker can process
        them in a valid order.

    }
    \end{itemize}
}
\item[Type Checker]
{
    \hfill
    \begin{itemize}
    \item
    {

        The type inference stage infers polymorphic overloaded types for each symbol, checks them against any
        user-provided type signatures, and alters the AST so that each expression is tagged with its type.

    }
    \item
    {

        Deoverloading converts polymorphic overloaded types to polymorphic types similar to those of System F, and
        alters the AST to implement typeclasses using dictionary-passing.

    }
    \end{itemize}
}
\item[Lowering]
{
    \hfill

    The lowering stage transforms the Haskell source AST into Intermediate Language A (ILA), then rearranges that
    tree into Administrative Normal Form (ILA-ANF), before finally transforming it into Intermediate Language B
    (ILB).

}
\item[Optimisations]
{
    \hfill

    Optimisations transform the intermediate languages while preserving their semantics.

    \todo[inline]{At time of writing these are done on ILB, might change to ILAANF so should update this accordingly.}
    \todo[inline]{If any more optimisations are implemented, update the diagram and here.}

}
\item[Code Generation]
{
    \hfill

    ILB is transformed into Java Bytecode (JVB), and a modified version of an existing library
    (hs-java\footnote{https://github.com/hnefatl/hs-java}) is used to convert a logical representation of the
    bytecode into a set of class files, which are then packaged into an executable Jar file.

}
\end{description}


\section{Implementation Details}
{
    \subsection{Frontend}
    {

        Lexing and parsing of Haskell source is performed using the
        \monospace{haskell-src}\footnote{https://hackage.haskell.org/package/haskell-src} library, which I have modified
        to provide some additional desirable features:

        \begin{itemize}
        \item
        {
            Lexing and parsing declarations for built-in constructors like list and tuple definitions (eg.\
            \haskell{data [] a = [] | a:[a]}).
        }
        \item
        {
            Parsing data declarations without any constructors (eg.\ \haskell{data Int})\footnote{Declarations of this
            form are invalid in the original Haskell 1998 syntax, but valid in Haskell 2010: see
            https://wiki.haskell.org/Empty\_type}. This is a valuable way of introducing built-in types.
        }
        \item
        {
            Adding \haskell{Hashable} and \haskell{Ord} typeclass instances to the syntax AST, so that syntax trees can
            be stored in associative containers.
        }
        \end{itemize}

        The syntax supported is a strict superset of Haskell 1998 and a strict subset of Haskell 2010, but my compiler
        does not have support for all of the features implied by the scope of the syntax. For example, multi-parameter
        typeclasses are parsed correctly as a feature of Haskell 2010 but get rejected by the deoverloading stage.

        \begin{figure}[h]
            \begin{haskellfigure}
            class Convertable a b where
                convert :: a -> b
            instance Convertable Bool Int where
                convert True = 1
                convert False = 0
            \end{haskellfigure}
            \caption{An example of a multi-parameter typeclass}
        \end{figure}

    }
    \subsection{Preprocessor}
    {
        \subsubsection{Renaming}
        {

            Haskell allows for multiple variables to share the same name within different scopes, which can increase the
            complexity of later stages in the pipeline. For example, when typechecking the following code we might
            conflate the two uses of \haskell{x}, and erroneously infer that they have the same type. A similar problem
            arises with variable shadowing, when the scopes overlap. The problem also applies to any type variables
            present in the source -- the type variable \haskell{a} is distinct between the two type signatures:

            \begin{haskellfigure}
            id :: a -> a
            id x = x

            const :: a -> b -> a
            const x _ = x
            \end{haskellfigure}

            Additionally, variables and type variables live in different worlds. The same token can refer to a variable
            and a type variable, even within the same scope -- the following code is perfectly valid (but loops
            forever):

            \begin{haskellfigure}
            x :: x
            x = x
            \end{haskellfigure}

            To eliminate the potential for subtle bugs stemming from this feature, the renamer pass gives each
            semantically distinct variable and type variable in the source a unique name. It traverses the syntax tree
            maintaining a mapping from syntactic variable names to a stack of unique semantic variable names
            (\haskell{Map VariableName [UniqueVariableName]}):

            \begin{itemize}
            \item When a new syntactic variable comes into scope (eg. from a let binding, a lambda argument, a new type signature, a pattern match...), a fresh semantic variable name is generated and pushed onto the stack.
            \item Whenever we leave the scope of a syntactic variable, we pop a semantic name off its corresponding
            stack.
            \item When we see a use of a syntactic variable, we replace it with the current top of the corresponding
            stack.
            \end{itemize}

            A similar mapping is maintained for type variables, with the same rules for maintaining it.

            Type constants such as \haskell{Bool} from \haskell{data Bool = False \| True} and typeclass names like
            \haskell{Num} from \haskell{class Num a where ...} are not renamed: these names are already guaranteed to be
            unique by the syntax of Haskell, and renaming them means we need to carry more state through the compiler as
            to what they've been renamed to.

        }
        \subsection{Kind/Class Analysis}
        {

            The typechecker and deoverloader require information about the kinds of any type constructors (the `type of
            the type', eg. \haskell{Int :: *} and \haskell{Maybe :: * -> *}), and the methods provided by different
            classes. This is tricky to compute during typechecking as that pass traverses the AST in dependency order.
            Instead, we just perform a traversal of the AST early in the pipeline to aggregate the required information.

        }
        \subsection{Dependency Analysis}
        {

            When typechecking, the order of processing declarations matters: we can't infer the type of \haskell{foo =
            bar baz} until we've inferred the types of \haskell{bar} and \haskell{baz}. The dependency analysis stage
            determines the order in which the typechecker should process declarations.
            
            We compute the sets of free/bound variables/type variables/type constants for each declaration, then
            construct a dependency graph -- each node is a declaration, and there's an edge from \(A\) to \(B\) if any
            of the bound variables/type variables/type constants at \(A\) are free in \(B\). It is important to
            distinguish between variables/type variables and type constants, as otherwise name conflicts could occur (as
            we don't rename type constants). This separation is upheld in the compiler by using different types for
            each, and is represented in the dependency graph below by colouring variables red and constants blue.
            
            The strongly connected components of the dependency graph correspond to sets of mutually recursive
            declarations, and the partial order between components gives us the order to typecheck each set. For
            example:

            \begin{figure}[H]
                \begin{haskellfigure}
                data Bool = False \| True   -- d1
                x = f True                  -- d2
                f y = g y                   -- d3
                g y = h y                   -- d4
                h y = f y                   -- d5
                \end{haskellfigure}
                \caption{}
                \label{code:dependency-graph}
            \end{figure}

            \begin{figure}[H]
                \includegraphics[width=0.5\textwidth]{figures/dependency_graph.png}
                \caption
                {
                    The dependency graph for Figure \ref{code:dependency-graph}. Variables in red, type
                    constants are in blue. Strongly connected components are highlighted.
                }
                \label{fig:dependency-graph}
            \end{figure}

            From the dependency graph, we know we have to typecheck \(d_2\) last, after both the trio of functions and
            after the datatype declaration. We also know that we need to typecheck the trio of functions together, as
            they're mutually recursive.

            This process works for languages without ad-hoc overloading, like SML. However, in Haskell there are some
            complications introduced by typeclasses:

            \begin{itemize}
            \item
            {

                Typeclass member variables can be declared multiple times within the same scope. For example:
                
                \begin{figure}[h]
                \begin{haskellfigure}
                class Num a where
                    (+) :: a -> a -> a
                instance Num Int where
                    x + y = ...
                instance Num Float where
                    x + y = ...
                \end{haskellfigure}
                \caption{}
                \label{code:valid-variable-reuse}
                \end{figure}

                Here the multiple declarations of \haskell{+} don't conflict: this is a valid program. However, the
                following program does have conflicting variables, as \haskell{x} is not a typeclass member and is not
                declared inside an \haskell{instance} declaration:

                \begin{figure}[h]
                \begin{haskellfigure}
                x = True
                x = False
                \end{haskellfigure}
                \caption{}
                \label{code:invalid-variable-reuse}
                \end{figure}

                These declaration conflicts can be expressed in a grid, where:

                \begin{itemize}
                \item
                {
                    
                    \monospace{SymDef |\(x\)|} and \monospace{SymType |\(x\)|} represent top-level declaration and
                    type-signature declarations for a symbol \(x\), like \haskell{|\(x\)| = True} and \haskell{|\(x\)| :: Bool}.

                }
                \item
                {
                    
                    \monospace{ClassSymDef |\(x\)| |\(c\)|} and \monospace{ClassSymType |\(x\)| |\(c\)|} represent
                    \monospace{SymDef |\(x\)|} and \monospace{SymType |\(x\)|} inside the declaration for a class \(c\),
                    like \haskell{class |\(c\)| where { |\(x\)| = True ; |\(x\)| :: Bool }}.

                }
                \item
                {

                    \monospace{InstSymDef |\(x\)| |\(c\)| |\(t\)|} represents a \monospace{SymType |\(x\)|} inside the
                    declaration for a class instance \(c\;t\), like \haskell{instance |\(c\)| |\(t\)| where { |\(x\)| = True }}.

                }
                \end{itemize}

                \begin{figure}[H]
                \small
                \setlength{\tabcolsep}{2pt}
                \begin{tabular}{ l | c c c c c }
                & \texttt{SymDef} \(x_1\) & \texttt{SymType} \(x_1\) & \texttt{ClassSymDef} \(x_1\) \(c_1\) &
                \texttt{ClassTypeDef} \(x_1\) \(c_1\) & \texttt{InstSymDef} \(x_1\) \(c_1\) \(t_1\) \\
                \hline
                \texttt{SymDef} \(x_2\) & \(x_1=x_2\) & \texttt{False} & \(x_1=x_2\) & \(x_1=x_2\) & \(x_1=x_2\) \\
                \texttt{SymType} \(x_2\) & & \(x_1=x_2\) & \(x_1=x_2\) & \(x_1=x_2\) & \(x_1=x_2\) \\
                \texttt{ClassSymDef} \(x_2\) \(c_2\) & & & \(x_1=x_2\) & \(x_1=x_2 \wedge c_1 \neq c_2\) & \(x_1=x_2 \wedge c_1 \neq c_2\) \\
                \texttt{ClassTypeDef} \(x_2\) \(c_2\) & & & & \(x_1=x_2\) & \(x_1=x_2 \wedge c_1 \neq c_2\) \\
                \texttt{InstSymDef} \(x_2\) \(c_2\) \(t_2\) & & & & & \(x_1=x_2 \wedge (c_1 \neq c_2 \vee t_1=t_2)\) \\
                \end{tabular}
                \end{figure}

                \todo[inline]{This table is too big... Could `factor out' the \(x_1 = x_2\) from all cells and remove the \(x\) params to free up space, but then it's less complete.}

                Using this table we can see that the multiple declarations for \haskell{+} in Figure
                \ref{code:valid-variable-reuse} do not conflict, while the declarations for \haskell{x} in Figure
                \ref{code:invalid-variable-reuse} do.

            }
            \item
            {

                Variable declarations such as \haskell{id = \\x -> x} are usually treated as being the unique binding
                definition of \haskell{id}, and any other uses within the same level of scope must be free rather than
                binding (otherwise we have conflicting definitions).
                
                However, we treat binding declarations inside \haskell{instance} declarations as actually being free
                uses rather than binding uses, so that the instance declaration forms a dependence on the class
                declaration where the variables are bound, ensuring it is typechecked first.

            }
            \item
            {

                The dependencies generated by this technique are \textit{syntactic}, not \textit{semantic}: the use of
                any ad-hoc overloaded variable generates dependencies on the class declaration that introduced the
                variable, but not the specific instance of the class that provides the definition of the variable used.
                Consider Figure \ref{code:syntactic-vs-semantic}:

                \begin{figure}[h]
                \begin{haskellfigure}
                class Foo a where
                    foo :: a -> Bool
                instance Foo Bool where
                    foo x = x
                instance Foo [Bool] where
                    foo xs = all foo xs
                \end{haskellfigure}
                \caption{}
                \label{code:syntactic-vs-semantic}
                \end{figure}

                The declaration of \haskell{foo} in \haskell{instance Foo [Bool]} semantically depends on the version of
                \haskell{foo} defined in \haskell{instance Foo Bool}, and yet no dependency will be generated between
                them as neither declaration binds \haskell{foo}: they will only generate dependencies to \haskell{class
                Foo a} (and to the declaration of \haskell{Bool} and \haskell{all}).

                Computing the semantic dependencies is too complicated to be done in this pass, so the problem is left
                and instead solved during the typechecking stage.

            }
            \end{itemize}

        }
    }
    \subsection{Type Checking}
    {

        Type inference and checking is the most complex part of the compiler pipeline. The type system implemented is
        intended to be similar to GHC's dialect of Haskell: approximately System \(\text{F}_\omega\) (the
        polymorphically typed lambda calculus with type constructors) along with algebraic data types and type classes
        to provide ad-hoc overloading. The approximation is due to a number of alterations made by the Haskell Report to
        ensure that type inference is decidable, along with the introduction of terms that aren't covered by the pure
        type system eg. literals such as \haskell{7} and \haskell{"foo"}. Finally, due to the complexity of the
        implementation there will doubtless be bugs affecting correctness in more complex cases not covered by tests.
        
        This is a subset of the type system used by GHC (System \(\text{F}_\text{C}\)), as that compiler provides
        extensions such as GADTs and type families requiring a more complex type system.

        \todo[inline]{Include examples of types demonstrating the features? Examples below might be sufficient. Think an appendix would be best, or should I just include here?}
        \todo[inline]{Include simple BNF grammar for the valid types: can modify the one on the HM wiki page}

        \todo[inline]{Substituion section explaining the basic notation? Used quite a lot in the next few subsubsections}

        \subsubsection{Type Inference}
        {

            The implementation is inspired by \cite{THIH}, and proceeds similarly to the Hindley-Milner (HM) type
            inference algorithm presented in \cite{HM-rules}. Following the naming convention using in \cite{THIH}, we
            refer to types such as \(\alpha\rightarrow\alpha\) as `simple types' (`monotypes' in HM), types with
            constraints such as \(\text{Eq}\alpha \Rightarrow \alpha\rightarrow\alpha\rightarrow\text{Bool}\) as
            `overloaded types', and types involving quantifiers such as \(\forall\alpha.\;\text{Monoid }\alpha
            \Rightarrow \alpha\rightarrow\alpha\rightarrow\alpha\) as `polymorphic types' (similar to `polytypes' in HM
            except the quantifiers may wrap an overloaded type or a simple type). It's often helpful to consider simple
            types as the special case of an overloaded type with an empty context (\(\emptyset \Rightarrow t\)).
            
            We process each declaration in dependency order, traversing the AST and tagging each expression with a type
            variable and unifying types together to derive a substitution from type variables to types. Each term in the
            syntax has an associated rule for combining the type variables representing the types of its sub-terms,
            which are computed recursively.

            One departure from the HM algorithm is that Haskell doesn't require \(\Lambda\) terms in the source language
            (explicit `forall' terms that generate \(\forall\) quantifiers on type variables): let-bound variables are
            implicitly polymorphic over all their free type variables, while function parameters are never polymorphic.
            In practice, this means that in Figure \ref{code:polymorphic-let}, \haskell{f :: |\(\forall \alpha.\;\alpha
            \rightarrow a\)|} whereas \haskell{g :: |\(\alpha \rightarrow \alpha\)|}. The difference in semantics
            ensures that type inference remains decidable.
 
            \begin{figure}[h]
            \begin{haskellfigure}
            let f x = x in const (f True) (f 1) :: Bool -- This is fine
            (\\g -> const (g True) (g 1)) (\x -> x)     -- This fails to typecheck
            \end{haskellfigure}
            \caption{}
            \label{code:polymorphic-let}
            \end{figure}
            
            Another major difference from HM is the introduction of typeclasses: whenever we encounter an overloaded
            variable such as \haskell{+}, we split the overloaded type into the constraints \(\{\text{Num }\alpha\}\)
            and the simple type \(\alpha\rightarrow\alpha\rightarrow\alpha\). Unification can be performed as in HM on
            the simple types, but we also maintain a global set of the constraints on type variables that we encounter.
            After unification has completed, we use this set to add the typeclass constraints to the inferred types.

            The final important difference from HM is in the instantiation of polymorphic types: the \([\texttt{Inst}]\)
            rule in HM allows for terms with polymorphic types to be reused with different argument types, but it needs
            a slight modification to handle type variable constraints introduced by overloaded types:
            
            \begin{figure*}[h]
            \centering
            \begin{subfigure}[t]{0.3\textwidth}
            \begin{displaymath}
            \prftree[r]{\([\text{Inst}]\)}
            {\prfassumption{\Gamma\vdash e : \tau'}}
            {\prfassumption{\tau' \sqsubseteq \tau}}
            {\Gamma\vdash e : \tau}
            \end{displaymath}
            \caption*{The original rule from HM}
            \end{subfigure}
            ~
            \begin{subfigure}[t]{0.6\textwidth}
            \begin{displaymath}
            \prftree[r]{\([\text{Inst}]\)}
            {\prfassumption{\Gamma\stackrel{\Delta}{\vdash} e : C\Rightarrow\tau'}}
            {\prfassumption{\tau' \sqsubseteq \tau}}
            {\prfassumption{\theta = \text{mgu}(\tau, \tau')}}
            {\Gamma\stackrel{\Delta\;\cup\;C\theta}{\vdash} e : C\theta\Rightarrow\tau}
            \end{displaymath}
            \caption*{A modified rule handling type classes. \(\Delta\) is the set of type variable constraints, built up throughout uses of the rules.}
            \end{subfigure}
            \end{figure*}

            \todo[inline]{Bother explaining \(\sqsubseteq\) or just say it means `x is more general than y'? Not exactly going into detail here anyway}

            Here is an example of how the type inference algorithm proceeds:

            \begin{haskellfigure}
            add1 x = x + 1
            y = add1 2
            \end{haskellfigure}

            We first process the declaration of \haskell{add1} as \haskell{y} depends on it, producing a
            type-variable-tagged AST and a substitution:

            \begin{figure}[H]
                \centering
                \begin{haskellfigure}
                add1|\(^\alpha\)| x|\(^\beta\)| = (((+)|\(^{\gamma \rightarrow \gamma \rightarrow \gamma}\)| x|\(^\beta\)|)|\(^\delta\)| 1|\(^\epsilon\)|)|\(^\eta\)|
                \end{haskellfigure}
            \end{figure}

            We know the type of \haskell{+} is \(\text{Num }\gamma \Rightarrow
            \gamma\rightarrow\gamma\rightarrow\gamma\) from the definition of \haskell{+} within the typeclass
            \haskell{Num}, which would have been processed prior to this example. We split the overloaded type into the
            type variable constraints (\(\{\text{Num }\gamma\}\)) and the simple type
            (\(\gamma\rightarrow\gamma\rightarrow\gamma\)), and use the simple type for unification and add the
            constraints to a global set of type variable constraints.

            \begin{figure}
                \centering
                \begin{equation*}
                \begin{split}
                    S_\text{add1} & = \text{mgu}(\alpha, \beta \rightarrow \eta) \circ \text{mgu}(\delta, \epsilon \rightarrow \eta) \circ \text{mgu}(\gamma\rightarrow\gamma\rightarrow\gamma, \beta \rightarrow \delta) \\
                                  & = [\sfrac{\gamma\rightarrow\gamma}{\alpha}, \sfrac{\gamma\rightarrow\gamma}{\delta}, \sfrac{\gamma}{\epsilon}, \sfrac{\gamma}{\eta}]
                \end{split}
                \end{equation*}
            \end{figure}

            The type of \haskell{add1} is therefore \(\alpha \; S_\text{add1} = \gamma\rightarrow\gamma\), and as this
            declaration is let-bound we insert quantifiers to make it polymorphic: \haskell{add1 :: |\(\forall\gamma.\;
            \gamma\rightarrow\gamma\)|}.

            Processing \haskell{y} gives:

            \begin{figure}[H]
            \begin{subfigure}[c]{\textwidth}
                \centering
                \begin{haskellfigure}
                y|\(^\iota\)| = (add1|\(^{\theta\rightarrow\theta}\)| 2|\(^\kappa\)|)|\(^\lambda\)|
                \end{haskellfigure}
            \end{subfigure}

            \begin{subfigure}[c]{\textwidth}
                \centering
                \begin{equation*}
                \begin{split}
                    S_\text{y} & = \text{mgu}(\iota, \lambda) \circ \text{mgu}(\theta\rightarrow\theta, \kappa\rightarrow\lambda) \\
                               & = [\sfrac{\theta}{\kappa}, \sfrac{\theta}{\iota}, \sfrac{\theta}{\lambda}]
                \end{split}
                \end{equation*}
            \end{subfigure}
            \end{figure}

            As \haskell{y} is let-bound again, we conclude \haskell{y :: |\(\forall \theta. \; \theta\)|}

            % Need to add typeclasses to all the above
            

        }

        % Instantiation of universal types
        % Pass for building substitution and doing tagging, pass for updating tags, pass for checking tags?
        % Patterns
        % Instance typing, with on-demand loading of instances. Refer back to renaming section
        % Mention Outside-In(X)
        % Mention Hindley-Milner is normally implemented impurely with a graph and updating references when types are
        % resolved. Could have done it that way (maybe should've), but didn't. Compiler is fully pure within the
        % pipeline.

    }
}

\end{document}